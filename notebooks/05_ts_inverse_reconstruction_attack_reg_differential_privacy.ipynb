{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_london_smartmeter = pd.read_csv(\"../data/LondonSmartMeter/london_smart_meters_dataset_without_missing_values_first_30_consumers.csv\", index_col='Time', parse_dates=['Time'])\n",
    "df_kddcup = pd.read_csv(\"../data/KDDCup_2018/kdd_cup_2018_dataset_without_missing_values.csv\", index_col='Time', parse_dates=['Time'])\n",
    "df_electricity_370 = pd.read_csv(\"../data/Electricity370/LD2011_2014_first_40_consumers.csv\", index_col='Time', parse_dates=['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device: NVIDIA L40S\n",
      "Physical cores: 64\n",
      "Total cores: 128\n",
      "Current Frequency: 3711.73Mhz\n",
      "Total: 1007.57 GB\n",
      "Available: 440.23 GB\n",
      "Used: 558.79 GB\n",
      "Percentage: 56.3%\n",
      "Distributed PyTorch available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import psutil\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the current device\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "    device = torch.cuda.current_device()\n",
    "    print(f\"Using CUDA device: {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"CUDA is not available\")\n",
    "\n",
    "print(\"Physical cores:\", psutil.cpu_count(logical=False))\n",
    "print(\"Total cores:\", psutil.cpu_count(logical=True))\n",
    "cpu_freq = psutil.cpu_freq()\n",
    "print(f\"Current Frequency: {cpu_freq.current:.2f}Mhz\")\n",
    "\n",
    "# RAM Information\n",
    "svmem = psutil.virtual_memory()\n",
    "print(f\"Total: {svmem.total / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Available: {svmem.available / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Used: {svmem.used / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Percentage: {svmem.percent}%\")\n",
    "\n",
    "print(\"Distributed PyTorch available:\", torch.distributed.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 24 processes\n",
      "def_c {'sign': True, 'defense_name': 'sign'}\n",
      "Starting attack 0 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defenses_5-3-2025a', 'seed': 10, 'number_of_batches': 5000, 'warmup_number_of_batches': 0, 'attack_number_of_batches': 1, 'batch_size': 1, 'device': 3, 'verbose': False, 'pool_size': 1, 'run_number': 0, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'evaluate_trained_model': True, 'attack_method': 'TS-Inverse', 'num_learn_epochs': 100, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0.5, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 0, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 1, 'features': [0], 'input_size': 96, 'output_size': 96, 'sign': True, 'defense_name': 'sign', 'model': 'FCN_Predictor', 'num_attack_steps': 0, 'train_dataset_size': 699}\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_sign_0_FCN_Predictor_0_electricity_370_5209_96_96_10_1.pt\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_sign_0_FCN_Predictor_0_electricity_370_4148_96_96_10_1.pt\n",
      "Saved inversion model to file.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def_c {'sign': True, 'defense_name': 'sign'}\n",
      "Starting attack 1 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defenses_5-3-2025a', 'seed': 10, 'number_of_batches': 5000, 'warmup_number_of_batches': 0, 'attack_number_of_batches': 1, 'batch_size': 1, 'device': 3, 'verbose': False, 'pool_size': 1, 'run_number': 1, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'evaluate_trained_model': True, 'attack_method': 'TS-Inverse', 'num_learn_epochs': 100, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0.5, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 5000, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 1, 'features': [0], 'input_size': 96, 'output_size': 96, 'sign': True, 'defense_name': 'sign', 'model': 'FCN_Predictor', 'num_attack_steps': 5000, 'train_dataset_size': 699}\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_sign_0_FCN_Predictor_0_electricity_370_5209_96_96_10_1.pt\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_sign_0_FCN_Predictor_0_electricity_370_4148_96_96_10_1.pt\n",
      "Saved inversion model to file.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def_c {'sign': True, 'defense_name': 'sign'}\n",
      "Starting attack 2 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defenses_5-3-2025a', 'seed': 43, 'number_of_batches': 5000, 'warmup_number_of_batches': 0, 'attack_number_of_batches': 1, 'batch_size': 1, 'device': 3, 'verbose': False, 'pool_size': 1, 'run_number': 2, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'evaluate_trained_model': True, 'attack_method': 'TS-Inverse', 'num_learn_epochs': 100, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0.5, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 0, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 1, 'features': [0], 'input_size': 96, 'output_size': 96, 'sign': True, 'defense_name': 'sign', 'model': 'FCN_Predictor', 'num_attack_steps': 0, 'train_dataset_size': 699}\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_sign_0_FCN_Predictor_0_electricity_370_5209_96_96_43_1.pt\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_sign_0_FCN_Predictor_0_electricity_370_4148_96_96_43_1.pt\n",
      "Saved inversion model to file.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def_c {'sign': True, 'defense_name': 'sign'}\n",
      "Starting attack 3 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defenses_5-3-2025a', 'seed': 43, 'number_of_batches': 5000, 'warmup_number_of_batches': 0, 'attack_number_of_batches': 1, 'batch_size': 1, 'device': 3, 'verbose': False, 'pool_size': 1, 'run_number': 3, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'evaluate_trained_model': True, 'attack_method': 'TS-Inverse', 'num_learn_epochs': 100, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0.5, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 5000, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 1, 'features': [0], 'input_size': 96, 'output_size': 96, 'sign': True, 'defense_name': 'sign', 'model': 'FCN_Predictor', 'num_attack_steps': 5000, 'train_dataset_size': 699}\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_sign_0_FCN_Predictor_0_electricity_370_5209_96_96_43_1.pt\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_sign_0_FCN_Predictor_0_electricity_370_4148_96_96_43_1.pt\n",
      "Saved inversion model to file.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def_c {'sign': True, 'defense_name': 'sign'}\n",
      "Starting attack 4 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defenses_5-3-2025a', 'seed': 28, 'number_of_batches': 5000, 'warmup_number_of_batches': 0, 'attack_number_of_batches': 1, 'batch_size': 1, 'device': 3, 'verbose': False, 'pool_size': 1, 'run_number': 4, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'evaluate_trained_model': True, 'attack_method': 'TS-Inverse', 'num_learn_epochs': 100, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0.5, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 0, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 1, 'features': [0], 'input_size': 96, 'output_size': 96, 'sign': True, 'defense_name': 'sign', 'model': 'FCN_Predictor', 'num_attack_steps': 0, 'train_dataset_size': 699}\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_sign_0_FCN_Predictor_0_electricity_370_5209_96_96_28_1.pt\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_sign_0_FCN_Predictor_0_electricity_370_4148_96_96_28_1.pt\n",
      "Saved inversion model to file.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def_c {'sign': True, 'defense_name': 'sign'}\n",
      "Starting attack 5 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defenses_5-3-2025a', 'seed': 28, 'number_of_batches': 5000, 'warmup_number_of_batches': 0, 'attack_number_of_batches': 1, 'batch_size': 1, 'device': 3, 'verbose': False, 'pool_size': 1, 'run_number': 5, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'evaluate_trained_model': True, 'attack_method': 'TS-Inverse', 'num_learn_epochs': 100, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0.5, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 5000, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 1, 'features': [0], 'input_size': 96, 'output_size': 96, 'sign': True, 'defense_name': 'sign', 'model': 'FCN_Predictor', 'num_attack_steps': 5000, 'train_dataset_size': 699}\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_sign_0_FCN_Predictor_0_electricity_370_5209_96_96_28_1.pt\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_sign_0_FCN_Predictor_0_electricity_370_4148_96_96_28_1.pt\n",
      "Saved inversion model to file.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def_c {'prune_rate': 0.1, 'defense_name': 'prune'}\n",
      "Starting attack 6 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defenses_5-3-2025a', 'seed': 10, 'number_of_batches': 5000, 'warmup_number_of_batches': 0, 'attack_number_of_batches': 1, 'batch_size': 1, 'device': 3, 'verbose': False, 'pool_size': 1, 'run_number': 6, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'evaluate_trained_model': True, 'attack_method': 'TS-Inverse', 'num_learn_epochs': 100, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0.5, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 0, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 1, 'features': [0], 'input_size': 96, 'output_size': 96, 'prune_rate': 0.1, 'defense_name': 'prune', 'model': 'FCN_Predictor', 'num_attack_steps': 0, 'train_dataset_size': 699}\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_prune_0_FCN_Predictor_0_electricity_370_5209_96_96_10_1.pt\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_prune_0_FCN_Predictor_0_electricity_370_4148_96_96_10_1.pt\n",
      "Saved inversion model to file.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def_c {'prune_rate': 0.1, 'defense_name': 'prune'}\n",
      "Starting attack 7 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defenses_5-3-2025a', 'seed': 10, 'number_of_batches': 5000, 'warmup_number_of_batches': 0, 'attack_number_of_batches': 1, 'batch_size': 1, 'device': 3, 'verbose': False, 'pool_size': 1, 'run_number': 7, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'evaluate_trained_model': True, 'attack_method': 'TS-Inverse', 'num_learn_epochs': 100, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0.5, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 5000, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 1, 'features': [0], 'input_size': 96, 'output_size': 96, 'prune_rate': 0.1, 'defense_name': 'prune', 'model': 'FCN_Predictor', 'num_attack_steps': 5000, 'train_dataset_size': 699}\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_prune_0_FCN_Predictor_0_electricity_370_5209_96_96_10_1.pt\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_prune_0_FCN_Predictor_0_electricity_370_4148_96_96_10_1.pt\n",
      "Saved inversion model to file.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def_c {'prune_rate': 0.1, 'defense_name': 'prune'}\n",
      "Starting attack 8 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defenses_5-3-2025a', 'seed': 43, 'number_of_batches': 5000, 'warmup_number_of_batches': 0, 'attack_number_of_batches': 1, 'batch_size': 1, 'device': 3, 'verbose': False, 'pool_size': 1, 'run_number': 8, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'evaluate_trained_model': True, 'attack_method': 'TS-Inverse', 'num_learn_epochs': 100, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0.5, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 0, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 1, 'features': [0], 'input_size': 96, 'output_size': 96, 'prune_rate': 0.1, 'defense_name': 'prune', 'model': 'FCN_Predictor', 'num_attack_steps': 0, 'train_dataset_size': 699}\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_prune_0_FCN_Predictor_0_electricity_370_5209_96_96_43_1.pt\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_prune_0_FCN_Predictor_0_electricity_370_4148_96_96_43_1.pt\n",
      "Saved inversion model to file.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def_c {'prune_rate': 0.1, 'defense_name': 'prune'}\n",
      "Starting attack 9 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defenses_5-3-2025a', 'seed': 43, 'number_of_batches': 5000, 'warmup_number_of_batches': 0, 'attack_number_of_batches': 1, 'batch_size': 1, 'device': 3, 'verbose': False, 'pool_size': 1, 'run_number': 9, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'evaluate_trained_model': True, 'attack_method': 'TS-Inverse', 'num_learn_epochs': 100, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0.5, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 5000, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 1, 'features': [0], 'input_size': 96, 'output_size': 96, 'prune_rate': 0.1, 'defense_name': 'prune', 'model': 'FCN_Predictor', 'num_attack_steps': 5000, 'train_dataset_size': 699}\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_prune_0_FCN_Predictor_0_electricity_370_5209_96_96_43_1.pt\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_prune_0_FCN_Predictor_0_electricity_370_4148_96_96_43_1.pt\n",
      "Saved inversion model to file.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def_c {'prune_rate': 0.1, 'defense_name': 'prune'}\n",
      "Starting attack 10 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defenses_5-3-2025a', 'seed': 28, 'number_of_batches': 5000, 'warmup_number_of_batches': 0, 'attack_number_of_batches': 1, 'batch_size': 1, 'device': 3, 'verbose': False, 'pool_size': 1, 'run_number': 10, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'evaluate_trained_model': True, 'attack_method': 'TS-Inverse', 'num_learn_epochs': 100, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0.5, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 0, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 1, 'features': [0], 'input_size': 96, 'output_size': 96, 'prune_rate': 0.1, 'defense_name': 'prune', 'model': 'FCN_Predictor', 'num_attack_steps': 0, 'train_dataset_size': 699}\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_prune_0_FCN_Predictor_0_electricity_370_5209_96_96_28_1.pt\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_prune_0_FCN_Predictor_0_electricity_370_4148_96_96_28_1.pt\n",
      "Saved inversion model to file.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def_c {'prune_rate': 0.1, 'defense_name': 'prune'}\n",
      "Starting attack 11 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defenses_5-3-2025a', 'seed': 28, 'number_of_batches': 5000, 'warmup_number_of_batches': 0, 'attack_number_of_batches': 1, 'batch_size': 1, 'device': 3, 'verbose': False, 'pool_size': 1, 'run_number': 11, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'evaluate_trained_model': True, 'attack_method': 'TS-Inverse', 'num_learn_epochs': 100, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0.5, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 5000, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 1, 'features': [0], 'input_size': 96, 'output_size': 96, 'prune_rate': 0.1, 'defense_name': 'prune', 'model': 'FCN_Predictor', 'num_attack_steps': 5000, 'train_dataset_size': 699}\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_prune_0_FCN_Predictor_0_electricity_370_5209_96_96_28_1.pt\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_prune_0_FCN_Predictor_0_electricity_370_4148_96_96_28_1.pt\n",
      "Saved inversion model to file.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def_c {'dp_epsilon': 0.1, 'defense_name': 'gauss'}\n",
      "Starting attack 12 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defenses_5-3-2025a', 'seed': 10, 'number_of_batches': 5000, 'warmup_number_of_batches': 0, 'attack_number_of_batches': 1, 'batch_size': 1, 'device': 3, 'verbose': False, 'pool_size': 1, 'run_number': 12, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'evaluate_trained_model': True, 'attack_method': 'TS-Inverse', 'num_learn_epochs': 100, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0.5, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 0, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 1, 'features': [0], 'input_size': 96, 'output_size': 96, 'dp_epsilon': 0.1, 'defense_name': 'gauss', 'model': 'FCN_Predictor', 'num_attack_steps': 0, 'train_dataset_size': 699}\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_gauss_0_FCN_Predictor_0_electricity_370_5209_96_96_10_1.pt\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_gauss_0_FCN_Predictor_0_electricity_370_4148_96_96_10_1.pt\n",
      "Saved inversion model to file.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def_c {'dp_epsilon': 0.1, 'defense_name': 'gauss'}\n",
      "Starting attack 13 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defenses_5-3-2025a', 'seed': 10, 'number_of_batches': 5000, 'warmup_number_of_batches': 0, 'attack_number_of_batches': 1, 'batch_size': 1, 'device': 3, 'verbose': False, 'pool_size': 1, 'run_number': 13, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'evaluate_trained_model': True, 'attack_method': 'TS-Inverse', 'num_learn_epochs': 100, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0.5, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 5000, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 1, 'features': [0], 'input_size': 96, 'output_size': 96, 'dp_epsilon': 0.1, 'defense_name': 'gauss', 'model': 'FCN_Predictor', 'num_attack_steps': 5000, 'train_dataset_size': 699}\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_gauss_0_FCN_Predictor_0_electricity_370_5209_96_96_10_1.pt\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_gauss_0_FCN_Predictor_0_electricity_370_4148_96_96_10_1.pt\n",
      "Saved inversion model to file.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def_c {'dp_epsilon': 0.1, 'defense_name': 'gauss'}\n",
      "Starting attack 14 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defenses_5-3-2025a', 'seed': 43, 'number_of_batches': 5000, 'warmup_number_of_batches': 0, 'attack_number_of_batches': 1, 'batch_size': 1, 'device': 3, 'verbose': False, 'pool_size': 1, 'run_number': 14, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'evaluate_trained_model': True, 'attack_method': 'TS-Inverse', 'num_learn_epochs': 100, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0.5, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 0, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 1, 'features': [0], 'input_size': 96, 'output_size': 96, 'dp_epsilon': 0.1, 'defense_name': 'gauss', 'model': 'FCN_Predictor', 'num_attack_steps': 0, 'train_dataset_size': 699}\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_gauss_0_FCN_Predictor_0_electricity_370_5209_96_96_43_1.pt\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_gauss_0_FCN_Predictor_0_electricity_370_4148_96_96_43_1.pt\n",
      "Saved inversion model to file.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def_c {'dp_epsilon': 0.1, 'defense_name': 'gauss'}\n",
      "Starting attack 15 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defenses_5-3-2025a', 'seed': 43, 'number_of_batches': 5000, 'warmup_number_of_batches': 0, 'attack_number_of_batches': 1, 'batch_size': 1, 'device': 3, 'verbose': False, 'pool_size': 1, 'run_number': 15, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'evaluate_trained_model': True, 'attack_method': 'TS-Inverse', 'num_learn_epochs': 100, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0.5, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 5000, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 1, 'features': [0], 'input_size': 96, 'output_size': 96, 'dp_epsilon': 0.1, 'defense_name': 'gauss', 'model': 'FCN_Predictor', 'num_attack_steps': 5000, 'train_dataset_size': 699}\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_gauss_0_FCN_Predictor_0_electricity_370_5209_96_96_43_1.pt\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_gauss_0_FCN_Predictor_0_electricity_370_4148_96_96_43_1.pt\n",
      "Saved inversion model to file.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def_c {'dp_epsilon': 0.1, 'defense_name': 'gauss'}\n",
      "Starting attack 16 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defenses_5-3-2025a', 'seed': 28, 'number_of_batches': 5000, 'warmup_number_of_batches': 0, 'attack_number_of_batches': 1, 'batch_size': 1, 'device': 3, 'verbose': False, 'pool_size': 1, 'run_number': 16, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'evaluate_trained_model': True, 'attack_method': 'TS-Inverse', 'num_learn_epochs': 100, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0.5, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 0, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 1, 'features': [0], 'input_size': 96, 'output_size': 96, 'dp_epsilon': 0.1, 'defense_name': 'gauss', 'model': 'FCN_Predictor', 'num_attack_steps': 0, 'train_dataset_size': 699}\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_gauss_0_FCN_Predictor_0_electricity_370_5209_96_96_28_1.pt\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_gauss_0_FCN_Predictor_0_electricity_370_4148_96_96_28_1.pt\n",
      "Saved inversion model to file.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def_c {'dp_epsilon': 0.1, 'defense_name': 'gauss'}\n",
      "Starting attack 17 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defenses_5-3-2025a', 'seed': 28, 'number_of_batches': 5000, 'warmup_number_of_batches': 0, 'attack_number_of_batches': 1, 'batch_size': 1, 'device': 3, 'verbose': False, 'pool_size': 1, 'run_number': 17, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'evaluate_trained_model': True, 'attack_method': 'TS-Inverse', 'num_learn_epochs': 100, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0.5, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 5000, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 1, 'features': [0], 'input_size': 96, 'output_size': 96, 'dp_epsilon': 0.1, 'defense_name': 'gauss', 'model': 'FCN_Predictor', 'num_attack_steps': 5000, 'train_dataset_size': 699}\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_gauss_0_FCN_Predictor_0_electricity_370_5209_96_96_28_1.pt\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_gauss_0_FCN_Predictor_0_electricity_370_4148_96_96_28_1.pt\n",
      "Saved inversion model to file.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def_c {'defense_name': 'none'}\n",
      "Starting attack 18 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defenses_5-3-2025a', 'seed': 10, 'number_of_batches': 5000, 'warmup_number_of_batches': 0, 'attack_number_of_batches': 1, 'batch_size': 1, 'device': 3, 'verbose': False, 'pool_size': 1, 'run_number': 18, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'evaluate_trained_model': True, 'attack_method': 'TS-Inverse', 'num_learn_epochs': 100, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0.5, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 0, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 1, 'features': [0], 'input_size': 96, 'output_size': 96, 'defense_name': 'none', 'model': 'FCN_Predictor', 'num_attack_steps': 0, 'train_dataset_size': 699}\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_none_0_FCN_Predictor_0_electricity_370_5209_96_96_10_1.pt\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_none_0_FCN_Predictor_0_electricity_370_4148_96_96_10_1.pt\n",
      "Saved inversion model to file.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def_c {'defense_name': 'none'}\n",
      "Starting attack 19 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defenses_5-3-2025a', 'seed': 10, 'number_of_batches': 5000, 'warmup_number_of_batches': 0, 'attack_number_of_batches': 1, 'batch_size': 1, 'device': 3, 'verbose': False, 'pool_size': 1, 'run_number': 19, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'evaluate_trained_model': True, 'attack_method': 'TS-Inverse', 'num_learn_epochs': 100, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0.5, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 5000, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 1, 'features': [0], 'input_size': 96, 'output_size': 96, 'defense_name': 'none', 'model': 'FCN_Predictor', 'num_attack_steps': 5000, 'train_dataset_size': 699}\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_none_0_FCN_Predictor_0_electricity_370_5209_96_96_10_1.pt\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_none_0_FCN_Predictor_0_electricity_370_4148_96_96_10_1.pt\n",
      "Saved inversion model to file.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def_c {'defense_name': 'none'}\n",
      "Starting attack 20 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defenses_5-3-2025a', 'seed': 43, 'number_of_batches': 5000, 'warmup_number_of_batches': 0, 'attack_number_of_batches': 1, 'batch_size': 1, 'device': 3, 'verbose': False, 'pool_size': 1, 'run_number': 20, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'evaluate_trained_model': True, 'attack_method': 'TS-Inverse', 'num_learn_epochs': 100, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0.5, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 0, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 1, 'features': [0], 'input_size': 96, 'output_size': 96, 'defense_name': 'none', 'model': 'FCN_Predictor', 'num_attack_steps': 0, 'train_dataset_size': 699}\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_none_0_FCN_Predictor_0_electricity_370_5209_96_96_43_1.pt\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_none_0_FCN_Predictor_0_electricity_370_4148_96_96_43_1.pt\n",
      "Saved inversion model to file.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def_c {'defense_name': 'none'}\n",
      "Starting attack 21 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defenses_5-3-2025a', 'seed': 43, 'number_of_batches': 5000, 'warmup_number_of_batches': 0, 'attack_number_of_batches': 1, 'batch_size': 1, 'device': 3, 'verbose': False, 'pool_size': 1, 'run_number': 21, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'evaluate_trained_model': True, 'attack_method': 'TS-Inverse', 'num_learn_epochs': 100, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0.5, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 5000, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 1, 'features': [0], 'input_size': 96, 'output_size': 96, 'defense_name': 'none', 'model': 'FCN_Predictor', 'num_attack_steps': 5000, 'train_dataset_size': 699}\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_none_0_FCN_Predictor_0_electricity_370_5209_96_96_43_1.pt\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_none_0_FCN_Predictor_0_electricity_370_4148_96_96_43_1.pt\n",
      "Saved inversion model to file.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def_c {'defense_name': 'none'}\n",
      "Starting attack 22 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defenses_5-3-2025a', 'seed': 28, 'number_of_batches': 5000, 'warmup_number_of_batches': 0, 'attack_number_of_batches': 1, 'batch_size': 1, 'device': 3, 'verbose': False, 'pool_size': 1, 'run_number': 22, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'evaluate_trained_model': True, 'attack_method': 'TS-Inverse', 'num_learn_epochs': 100, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0.5, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 0, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 1, 'features': [0], 'input_size': 96, 'output_size': 96, 'defense_name': 'none', 'model': 'FCN_Predictor', 'num_attack_steps': 0, 'train_dataset_size': 699}\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_none_0_FCN_Predictor_0_electricity_370_5209_96_96_28_1.pt\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_none_0_FCN_Predictor_0_electricity_370_4148_96_96_28_1.pt\n",
      "Saved inversion model to file.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def_c {'defense_name': 'none'}\n",
      "Starting attack 23 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defenses_5-3-2025a', 'seed': 28, 'number_of_batches': 5000, 'warmup_number_of_batches': 0, 'attack_number_of_batches': 1, 'batch_size': 1, 'device': 3, 'verbose': False, 'pool_size': 1, 'run_number': 23, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'evaluate_trained_model': True, 'attack_method': 'TS-Inverse', 'num_learn_epochs': 100, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0.5, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 5000, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 1, 'features': [0], 'input_size': 96, 'output_size': 96, 'defense_name': 'none', 'model': 'FCN_Predictor', 'num_attack_steps': 5000, 'train_dataset_size': 699}\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_none_0_FCN_Predictor_0_electricity_370_5209_96_96_28_1.pt\n",
      "Loaded gradient to inputs targets dataset: ../data/_model_dataset_gradients/grad_inputs_targets_dataset_none_0_FCN_Predictor_0_electricity_370_4148_96_96_28_1.pt\n",
      "Saved inversion model to file.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from ts_inverse.models import (\n",
    "    FCN_Predictor,\n",
    "    CNN_Predictor,\n",
    "    GRU_Predictor,\n",
    "    JitGRU_Predictor,\n",
    "    CNNJitGRU_Predictor,\n",
    "    TCN_Predictor,\n",
    "    JitSeq2Seq_Predictor,\n",
    ")\n",
    "from ts_inverse.utils import grid_search_params\n",
    "from ts_inverse.workers import AttackTSInverseWorker\n",
    "\n",
    "\n",
    "def start_multi_process(g_config, a_config, d_config, m_config, def_config, pool_size):\n",
    "    search_args = []\n",
    "    search_configs = list(grid_search_params(g_config))\n",
    "    search_attack_configs = list(grid_search_params(a_config))\n",
    "    search_dataset_settings = list(grid_search_params(d_config))\n",
    "    search_model_settings = list(grid_search_params(m_config))\n",
    "    search_defense_settings = list(grid_search_params(def_config))\n",
    "    for def_config in search_defense_settings:\n",
    "        for original_g_config in search_configs:\n",
    "            for a_config in search_attack_configs:\n",
    "                g_config = deepcopy(original_g_config)\n",
    "                g_config.update(a_config)\n",
    "                for m_config in search_model_settings:\n",
    "                    for d_config in search_dataset_settings:\n",
    "                        fa_models_config = {\n",
    "                            \"features\": [[0]],\n",
    "                            \"input_size\": d_config[\"observation_days\"],\n",
    "                            \"output_size\": d_config[\"future_days\"],\n",
    "                        }\n",
    "                        search_for_all_models_settings = list(grid_search_params(fa_models_config))\n",
    "                        for fa_models_config in search_for_all_models_settings:\n",
    "                            g_config[\"run_number\"] = len(search_args)\n",
    "                            args = (g_config, d_config, m_config, fa_models_config, def_config)\n",
    "                            search_args.append(deepcopy(args))\n",
    "\n",
    "    print(f\"Starting {len(search_args)} processes\")\n",
    "    if pool_size == 1:\n",
    "        for args in search_args:\n",
    "            AttackTSInverseWorker(args[0][\"run_number\"]).worker_process(*args)\n",
    "\n",
    "\n",
    "global_config = {\n",
    "    \"logger_service\": \"wandb\",\n",
    "    \"experiment_name\": \"ts-inverse_defenses_5-3-2025a\",\n",
    "    \"seed\": [10, 43, 28],  # 28, 80, 71],\n",
    "    \"number_of_batches\": 5000,  # Training steps\n",
    "    \"warmup_number_of_batches\": 0,\n",
    "    \"attack_number_of_batches\": 1,\n",
    "    \"batch_size\": 1,  # Federated learning batch size\n",
    "    \"device\": 3,\n",
    "    \"verbose\": False,\n",
    "    \"pool_size\": 1,\n",
    "    \"run_number\": -1,\n",
    "    \"total_variation_alpha_inputs\": 0,\n",
    "    \"total_variation_beta_targets\": 0,\n",
    "    \"after_effect\": \"none\",\n",
    "    \"update_model\": True,  # Update the model in generating gradients from training data\n",
    "    \"model_evaluation_during_attack\": False,\n",
    "    \"load_lti_model\": False,\n",
    "    \"dropout\": 0,\n",
    "    \"optimize_dropout\": False,\n",
    "    \"dropout_probability_regularizer\": 0,\n",
    "    \"dummy_init_method\": \"rand\",\n",
    "    \"evaluate_trained_model\": True,\n",
    "}\n",
    "\n",
    "defense_config = [\n",
    "    {\n",
    "        \"sign\": True,\n",
    "        \"defense_name\": \"sign\",\n",
    "    },\n",
    "    {\n",
    "        \"prune_rate\": [0.1],\n",
    "        \"defense_name\": \"prune\",\n",
    "    },\n",
    "    {\n",
    "        \"dp_epsilon\": [0.1],\n",
    "        \"defense_name\": \"gauss\",\n",
    "    },\n",
    "    {\n",
    "        \"defense_name\": \"none\",\n",
    "    },  # No defense\n",
    "]\n",
    "\n",
    "attack_config = [\n",
    "    {\n",
    "        \"attack_method\": \"TS-Inverse\",\n",
    "        # invert attack\n",
    "        \"num_learn_epochs\": 100,\n",
    "        \"learn_learning_rate\": 1e-3,\n",
    "        \"attack_batch_size\": 32,\n",
    "        \"inversion_batch_size\": 1,  # global_config['batch_size'],\n",
    "        \"attack_hidden_size\": [[768, 512]],\n",
    "        \"quantiles\": [[0.1, 0.3, 0.7, 0.9]],\n",
    "        \"attack_loss\": [\"quantile\"],\n",
    "        \"inversion_model\": \"ImprovedGradToInputNN_Quantile\",\n",
    "        \"attack_targets\": True,\n",
    "        \"learn_optimizer\": \"adamW\",\n",
    "        \"learn_lr_decay\": [\"on_plateau\"],\n",
    "        \"aux_dataset\": None,\n",
    "        'one_shot_targets': False,\n",
    "\n",
    "        ## Inversion regularization in optimization attack\n",
    "        \"inversion_regularization_term_inputs\": [1],\n",
    "        \"inversion_regularization_term_targets\": [0.1],\n",
    "        \"inversion_regularization_loss\": [\"quantile_bounds\"],\n",
    "        \"lower_res_term_inputs\": [0],\n",
    "        \"lower_res_term_targets\": [0],\n",
    "        \"periodicity_term\": [1],\n",
    "        \"periodicity_loss\": [\"l1_mean\"],\n",
    "        \"periodicity_reduce_lr\": [False],\n",
    "        \"trend_term\": [0.5],\n",
    "        \"trend_loss\": [\"l1_mean\"],\n",
    "        \"trend_reduce_lr\": [False],\n",
    "\n",
    "        ## Optimization attack\n",
    "        \"gradient_loss\": \"l1\",\n",
    "        \"base_num_attack_steps\": [0, 5000],\n",
    "        \"after_effect\": \"clamp_2\",\n",
    "        \"optimization_learning_rate\": 0.01,\n",
    "        \"attack_opti_optimizer\": [\"adam\"],\n",
    "        \"attack_opti_lr_decay\": [\"on_plateau_10\"],\n",
    "        \"optimize_dropout\": True,\n",
    "        \"clamp_dropout\": 1,\n",
    "        \"clamp_dropout_min_max\": [[0.0, 1.0]],\n",
    "        \"dropout_probability_regularizer\": [1e-5],  # 1e-6, 1e-7, 1e-8],\n",
    "        \"dropout_probability_reg_error\": \"abs\",\n",
    "        \"dropout_mask_init_type\": \"halves\",  # ['bernoulli', 'halves', 'uniform', 'p', '1-p'], #['halves', 'bernoulli'],\n",
    "        \"grad_signs_for_inputs\": True,\n",
    "        \"grad_signs_for_targets\": False,\n",
    "        \"grad_signs_for_dropouts\": True,  # [False, True],\n",
    "    },\n",
    "]\n",
    "\n",
    "dataset_config = [\n",
    "    {\n",
    "        \"dataset\": \"electricity_370\",\n",
    "        \"columns\": [df_electricity_370.columns.tolist()[4:5]],\n",
    "        \"train_stride\": 24,\n",
    "        \"validation_stride\": 1,\n",
    "        \"observation_days\": 1,\n",
    "        \"future_days\": 1,\n",
    "        \"normalize\": \"minmax\",\n",
    "    },\n",
    "    # {\n",
    "    #     'dataset': 'london_smartmeter',\n",
    "    #     'columns': [df_london_smartmeter.columns.tolist()[:1]],\n",
    "    #     'train_stride': 24, # Is the strides that are attacked\n",
    "    #     'validation_stride': 1, # Is the stride that is used for training the invertion model\n",
    "    #     'observation_days': 1,\n",
    "    #     'future_days': 1,\n",
    "    #     'normalize': 'minmax',\n",
    "    # },\n",
    "    # {\n",
    "    #     'dataset': 'kddcup',\n",
    "    #     'columns': [df_kddcup.columns.tolist()[:1]],\n",
    "    #     'train_stride': 24,\n",
    "    #     'validation_stride': 1,\n",
    "    #     'observation_days': 5,\n",
    "    #     'future_days': 2,\n",
    "    #     'normalize': 'minmax',\n",
    "    # },\n",
    "]\n",
    "\n",
    "model_config = [\n",
    "    # {\n",
    "    #     '_model': CNN_Predictor,\n",
    "    #     'hidden_size': 64,\n",
    "    #     '_attack_step_multiplier': 10,\n",
    "    # },\n",
    "    {\n",
    "        \"_model\": FCN_Predictor,\n",
    "        \"hidden_size\": 64,\n",
    "        \"_attack_step_multiplier\": 1,\n",
    "    },\n",
    "    # {\n",
    "    #     '_model': TCN_Predictor,\n",
    "    #     'hidden_size': 64,\n",
    "    #     'num_levels': 0,\n",
    "    #     'kernel_size': 6,\n",
    "    #     'dilation_factor': 2,\n",
    "    #     'activation': 'relu',\n",
    "    #     'use_weight_norm': True,\n",
    "    #     'init_weights': True,\n",
    "    #     'dropout': 0.1,\n",
    "    #     '_attack_step_multiplier': 10,\n",
    "    # },\n",
    "    # {\n",
    "    #     '_model': JitGRU_Predictor,\n",
    "    #     'hidden_size': 64,\n",
    "    #     '_attack_step_multiplier': 10,\n",
    "    # },\n",
    "    # {\n",
    "    #     '_model': JitSeq2Seq_Predictor,\n",
    "    #     'hidden_size': 64,\n",
    "    #     '_attack_step_multiplier': 10,\n",
    "    # }\n",
    "]\n",
    "\n",
    "start_multi_process(global_config, attack_config, dataset_config, model_config, defense_config, global_config[\"pool_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
