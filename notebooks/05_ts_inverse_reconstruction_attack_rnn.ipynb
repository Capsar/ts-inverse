{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_london_smartmeter = pd.read_csv(\"./data/LondonSmartMeter/london_smart_meters_dataset_without_missing_values_first_30_consumers.csv\", index_col='Time', parse_dates=['Time'])\n",
    "df_kddcup = pd.read_csv(\"./data/KDDCup_2018/kdd_cup_2018_dataset_without_missing_values.csv\", index_col='Time', parse_dates=['Time'])\n",
    "df_electricity_370 = pd.read_csv(\"./data/Electricity370/LD2011_2014_first_40_consumers.csv\", index_col='Time', parse_dates=['Time'])\n",
    "# tno_df.head()\n",
    "# print(df.columns.tolist()[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available\n",
      "Physical cores: 14\n",
      "Total cores: 20\n",
      "Current Frequency: 2300.00Mhz\n",
      "Total: 15.70 GB\n",
      "Available: 3.66 GB\n",
      "Used: 12.04 GB\n",
      "Percentage: 76.7%\n",
      "Distributed PyTorch available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import psutil\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the current device\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "    device = torch.cuda.current_device()\n",
    "    print(f\"Using CUDA device: {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"CUDA is not available\")\n",
    "\n",
    "print(\"Physical cores:\", psutil.cpu_count(logical=False))\n",
    "print(\"Total cores:\", psutil.cpu_count(logical=True))\n",
    "cpu_freq = psutil.cpu_freq()\n",
    "print(f\"Current Frequency: {cpu_freq.current:.2f}Mhz\")\n",
    "\n",
    "# RAM Information\n",
    "svmem = psutil.virtual_memory()\n",
    "print(f\"Total: {svmem.total / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Available: {svmem.available / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Used: {svmem.used / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Percentage: {svmem.percent}%\")\n",
    "\n",
    "print(\"Distributed PyTorch available:\", torch.distributed.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 4 processes\n",
      "Starting attack 0 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_defense_06-07-2024', 'seed': 10, 'batch_size': 1, 'device': 'cpu', 'verbose': False, 'pool_size': 1, 'run_number': 0, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'warmup_number_of_batches': 0, 'number_of_batches': 1, 'update_model': True, 'model_evaluation_during_attack': False, 'load_lti_model': True, 'dropout': 0, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'attack_method': 'TS-Inverse', 'num_learn_epochs': 75, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'one_shot_targets': False, 'inversion_regularization_term_inputs': 1, 'inversion_regularization_term_targets': 0.1, 'inversion_regularization_loss': 'quantile_bounds', 'inversion_dilation_loss_alpha_gamma': [0.1, 0.9], 'lower_res_term_inputs': 0, 'lower_res_term_targets': 0, 'periodicity_term': 1, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'trend_term': 0, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 500, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_probability_reg_error': 'abs', 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, '_attack_step_multiplier': 10, 'features': [0], 'input_size': 96, 'output_size': 96, 'model': 'JitGRU_Predictor', 'num_attack_steps': 5000, 'train_dataset_size': 699}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\caspa\\Documents\\01_SoftwareDevelopmentLocation\\VS Code\\ts-inverse\\05_ts_inverse_reconstruction_attack_rnn.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/caspa/Documents/01_SoftwareDevelopmentLocation/VS%20Code/ts-inverse/05_ts_inverse_reconstruction_attack_rnn.ipynb#W3sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m dataset_config \u001b[39m=\u001b[39m [\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/caspa/Documents/01_SoftwareDevelopmentLocation/VS%20Code/ts-inverse/05_ts_inverse_reconstruction_attack_rnn.ipynb#W3sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m     {\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/caspa/Documents/01_SoftwareDevelopmentLocation/VS%20Code/ts-inverse/05_ts_inverse_reconstruction_attack_rnn.ipynb#W3sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39melectricity_370\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/caspa/Documents/01_SoftwareDevelopmentLocation/VS%20Code/ts-inverse/05_ts_inverse_reconstruction_attack_rnn.ipynb#W3sZmlsZQ%3D%3D?line=148'>149</a>\u001b[0m     \u001b[39m# },    \u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/caspa/Documents/01_SoftwareDevelopmentLocation/VS%20Code/ts-inverse/05_ts_inverse_reconstruction_attack_rnn.ipynb#W3sZmlsZQ%3D%3D?line=149'>150</a>\u001b[0m ]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/caspa/Documents/01_SoftwareDevelopmentLocation/VS%20Code/ts-inverse/05_ts_inverse_reconstruction_attack_rnn.ipynb#W3sZmlsZQ%3D%3D?line=151'>152</a>\u001b[0m model_config \u001b[39m=\u001b[39m [\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/caspa/Documents/01_SoftwareDevelopmentLocation/VS%20Code/ts-inverse/05_ts_inverse_reconstruction_attack_rnn.ipynb#W3sZmlsZQ%3D%3D?line=152'>153</a>\u001b[0m     \u001b[39m# {\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/caspa/Documents/01_SoftwareDevelopmentLocation/VS%20Code/ts-inverse/05_ts_inverse_reconstruction_attack_rnn.ipynb#W3sZmlsZQ%3D%3D?line=153'>154</a>\u001b[0m     \u001b[39m#     '_model': CNN_Predictor,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/caspa/Documents/01_SoftwareDevelopmentLocation/VS%20Code/ts-inverse/05_ts_inverse_reconstruction_attack_rnn.ipynb#W3sZmlsZQ%3D%3D?line=183'>184</a>\u001b[0m     }\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/caspa/Documents/01_SoftwareDevelopmentLocation/VS%20Code/ts-inverse/05_ts_inverse_reconstruction_attack_rnn.ipynb#W3sZmlsZQ%3D%3D?line=184'>185</a>\u001b[0m ]\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/caspa/Documents/01_SoftwareDevelopmentLocation/VS%20Code/ts-inverse/05_ts_inverse_reconstruction_attack_rnn.ipynb#W3sZmlsZQ%3D%3D?line=186'>187</a>\u001b[0m start_multi_process(global_config, attack_config, dataset_config, model_config, global_config[\u001b[39m'\u001b[39m\u001b[39mpool_size\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;32mc:\\Users\\caspa\\Documents\\01_SoftwareDevelopmentLocation\\VS Code\\ts-inverse\\05_ts_inverse_reconstruction_attack_rnn.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/caspa/Documents/01_SoftwareDevelopmentLocation/VS%20Code/ts-inverse/05_ts_inverse_reconstruction_attack_rnn.ipynb#W3sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mif\u001b[39;00m pool_size \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/caspa/Documents/01_SoftwareDevelopmentLocation/VS%20Code/ts-inverse/05_ts_inverse_reconstruction_attack_rnn.ipynb#W3sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39mfor\u001b[39;00m args \u001b[39min\u001b[39;00m search_args:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/caspa/Documents/01_SoftwareDevelopmentLocation/VS%20Code/ts-inverse/05_ts_inverse_reconstruction_attack_rnn.ipynb#W3sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         AttackTSInverseWorker(args[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mrun_number\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mworker_process(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\caspa\\Documents\\01_SoftwareDevelopmentLocation\\VS Code\\ts-inverse\\src\\workers\\attack_ts_inverse_worker.py:43\u001b[0m, in \u001b[0;36mAttackTSInverseWorker.worker_process\u001b[1;34m(self, c, d_c, m_c, fam_c)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_logger_object(final_config)\n\u001b[0;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_attack(model, train_dataloader, final_config)\n\u001b[1;32m---> 43\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart_attack(model, config\u001b[39m=\u001b[39mfinal_config)\n\u001b[0;32m     44\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_end_logger_object()\n",
      "File \u001b[1;32mc:\\Users\\caspa\\Documents\\01_SoftwareDevelopmentLocation\\VS Code\\ts-inverse\\src\\workers\\attack_dlg_invg_dia_worker.py:75\u001b[0m, in \u001b[0;36mAttackBaselineWorker.start_attack\u001b[1;34m(self, model, config)\u001b[0m\n\u001b[0;32m     72\u001b[0m     batch_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_batch_inputs[batch_number]\n\u001b[0;32m     73\u001b[0m     batch_targets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_batch_targets[batch_number]\n\u001b[1;32m---> 75\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattack_batch(model, config, batch_number, original_dy_dx, dummy_inputs, dummy_targets, batch_inputs, batch_targets)\n\u001b[0;32m     77\u001b[0m \u001b[39mif\u001b[39;00m config[\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n",
      "File \u001b[1;32mc:\\Users\\caspa\\Documents\\01_SoftwareDevelopmentLocation\\VS Code\\ts-inverse\\src\\workers\\attack_ts_inverse_worker.py:56\u001b[0m, in \u001b[0;36mAttackTSInverseWorker.attack_batch\u001b[1;34m(self, model, config, batch_number, original_dy_dx, dummy_inputs, dummy_targets, batch_inputs, batch_targets)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mattack_batch\u001b[39m(\u001b[39mself\u001b[39m, model, config, batch_number, original_dy_dx, dummy_inputs, dummy_targets, batch_inputs, batch_targets):\n\u001b[0;32m     54\u001b[0m \n\u001b[0;32m     55\u001b[0m     \u001b[39m# Get the inversion model from super class.\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m     inversion_model \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mattack_batch(model, config, batch_number, original_dy_dx, dummy_inputs, dummy_targets, batch_inputs, batch_targets)\n\u001b[0;32m     58\u001b[0m     \u001b[39mif\u001b[39;00m config[\u001b[39m'\u001b[39m\u001b[39mnum_attack_steps\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     59\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\caspa\\Documents\\01_SoftwareDevelopmentLocation\\VS Code\\ts-inverse\\src\\workers\\attack_learning_to_invert_worker.py:119\u001b[0m, in \u001b[0;36mAttackLearningToInvertWorker.attack_batch\u001b[1;34m(self, model, config, batch_number, original_dy_dx, dummy_inputs, dummy_targets, batch_inputs, batch_targets)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, config[\u001b[39m'\u001b[39m\u001b[39mnum_learn_epochs\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m--> 119\u001b[0m         epoch_t_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minversion_model_epoch(config, epoch, aux_gi_t_dataloader, inversion_model, grad_to_input_optimizer, lr_schedular)\n\u001b[0;32m    120\u001b[0m         epoch_v_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minversion_model_epoch(config, epoch, aux_gi_v_dataloader, inversion_model)\n\u001b[0;32m    122\u001b[0m         attack_metrics \u001b[39m=\u001b[39m {\n\u001b[0;32m    123\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m: epoch,\n\u001b[0;32m    124\u001b[0m             \u001b[39m'\u001b[39m\u001b[39maux_t_loss\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mmean(epoch_t_loss),\n\u001b[0;32m    125\u001b[0m             \u001b[39m'\u001b[39m\u001b[39maux_v_loss\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mmean(epoch_v_loss)\n\u001b[0;32m    126\u001b[0m         }\n",
      "File \u001b[1;32mc:\\Users\\caspa\\Documents\\01_SoftwareDevelopmentLocation\\VS Code\\ts-inverse\\src\\workers\\attack_learning_to_invert_worker.py:234\u001b[0m, in \u001b[0;36mAttackLearningToInvertWorker.inversion_model_epoch\u001b[1;34m(self, config, epoch, aux_gi_dataloader, inversion_model, grad_to_input_optimizer, lr_schedular)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39mif\u001b[39;00m grad_to_input_optimizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m--> 234\u001b[0m     grad_to_input_optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m    236\u001b[0m epoch_loss\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mitem())\n\u001b[0;32m    237\u001b[0m \u001b[39mif\u001b[39;00m config[\u001b[39m'\u001b[39m\u001b[39mverbose\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\caspa\\miniconda3\\envs\\thesis_fl_cuda\\Lib\\site-packages\\torch\\optim\\optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    382\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m             )\n\u001b[1;32m--> 385\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    386\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    388\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\caspa\\miniconda3\\envs\\thesis_fl_cuda\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\caspa\\miniconda3\\envs\\thesis_fl_cuda\\Lib\\site-packages\\torch\\optim\\adamw.py:187\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    174\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m\"\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    176\u001b[0m     has_complex \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[0;32m    177\u001b[0m         group,\n\u001b[0;32m    178\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m         state_steps,\n\u001b[0;32m    185\u001b[0m     )\n\u001b[1;32m--> 187\u001b[0m     adamw(\n\u001b[0;32m    188\u001b[0m         params_with_grad,\n\u001b[0;32m    189\u001b[0m         grads,\n\u001b[0;32m    190\u001b[0m         exp_avgs,\n\u001b[0;32m    191\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    192\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    193\u001b[0m         state_steps,\n\u001b[0;32m    194\u001b[0m         amsgrad\u001b[39m=\u001b[39mamsgrad,\n\u001b[0;32m    195\u001b[0m         beta1\u001b[39m=\u001b[39mbeta1,\n\u001b[0;32m    196\u001b[0m         beta2\u001b[39m=\u001b[39mbeta2,\n\u001b[0;32m    197\u001b[0m         lr\u001b[39m=\u001b[39mgroup[\u001b[39m\"\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    198\u001b[0m         weight_decay\u001b[39m=\u001b[39mgroup[\u001b[39m\"\u001b[39m\u001b[39mweight_decay\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    199\u001b[0m         eps\u001b[39m=\u001b[39mgroup[\u001b[39m\"\u001b[39m\u001b[39meps\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    200\u001b[0m         maximize\u001b[39m=\u001b[39mgroup[\u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    201\u001b[0m         foreach\u001b[39m=\u001b[39mgroup[\u001b[39m\"\u001b[39m\u001b[39mforeach\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    202\u001b[0m         capturable\u001b[39m=\u001b[39mgroup[\u001b[39m\"\u001b[39m\u001b[39mcapturable\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    203\u001b[0m         differentiable\u001b[39m=\u001b[39mgroup[\u001b[39m\"\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    204\u001b[0m         fused\u001b[39m=\u001b[39mgroup[\u001b[39m\"\u001b[39m\u001b[39mfused\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    205\u001b[0m         grad_scale\u001b[39m=\u001b[39m\u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgrad_scale\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m    206\u001b[0m         found_inf\u001b[39m=\u001b[39m\u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfound_inf\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m    207\u001b[0m         has_complex\u001b[39m=\u001b[39mhas_complex,\n\u001b[0;32m    208\u001b[0m     )\n\u001b[0;32m    210\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\caspa\\miniconda3\\envs\\thesis_fl_cuda\\Lib\\site-packages\\torch\\optim\\adamw.py:339\u001b[0m, in \u001b[0;36madamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    337\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adamw\n\u001b[1;32m--> 339\u001b[0m func(\n\u001b[0;32m    340\u001b[0m     params,\n\u001b[0;32m    341\u001b[0m     grads,\n\u001b[0;32m    342\u001b[0m     exp_avgs,\n\u001b[0;32m    343\u001b[0m     exp_avg_sqs,\n\u001b[0;32m    344\u001b[0m     max_exp_avg_sqs,\n\u001b[0;32m    345\u001b[0m     state_steps,\n\u001b[0;32m    346\u001b[0m     amsgrad\u001b[39m=\u001b[39mamsgrad,\n\u001b[0;32m    347\u001b[0m     beta1\u001b[39m=\u001b[39mbeta1,\n\u001b[0;32m    348\u001b[0m     beta2\u001b[39m=\u001b[39mbeta2,\n\u001b[0;32m    349\u001b[0m     lr\u001b[39m=\u001b[39mlr,\n\u001b[0;32m    350\u001b[0m     weight_decay\u001b[39m=\u001b[39mweight_decay,\n\u001b[0;32m    351\u001b[0m     eps\u001b[39m=\u001b[39meps,\n\u001b[0;32m    352\u001b[0m     maximize\u001b[39m=\u001b[39mmaximize,\n\u001b[0;32m    353\u001b[0m     capturable\u001b[39m=\u001b[39mcapturable,\n\u001b[0;32m    354\u001b[0m     differentiable\u001b[39m=\u001b[39mdifferentiable,\n\u001b[0;32m    355\u001b[0m     grad_scale\u001b[39m=\u001b[39mgrad_scale,\n\u001b[0;32m    356\u001b[0m     found_inf\u001b[39m=\u001b[39mfound_inf,\n\u001b[0;32m    357\u001b[0m     has_complex\u001b[39m=\u001b[39mhas_complex,\n\u001b[0;32m    358\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\caspa\\miniconda3\\envs\\thesis_fl_cuda\\Lib\\site-packages\\torch\\optim\\adamw.py:470\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[0;32m    468\u001b[0m         denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m    469\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 470\u001b[0m         denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m    472\u001b[0m     param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n\u001b[0;32m    474\u001b[0m \u001b[39m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from ts_inverse.models import FCN_Predictor, CNN_Predictor, GRU_Predictor, JitGRU_Predictor, CNNJitGRU_Predictor, TCN_Predictor, JitSeq2Seq_Predictor\n",
    "from ts_inverse.utils import grid_search_params\n",
    "from ts_inverse.workers import AttackTSInverseWorker\n",
    "\n",
    "\n",
    "def start_multi_process(g_config, a_config, d_config, m_config, pool_size):\n",
    "    search_args = []\n",
    "    search_configs = list(grid_search_params(g_config))\n",
    "    search_attack_configs = list(grid_search_params(a_config))\n",
    "    search_dataset_settings = list(grid_search_params(d_config))\n",
    "    search_model_settings = list(grid_search_params(m_config))\n",
    "    for original_g_config in search_configs:\n",
    "        for a_config in search_attack_configs:\n",
    "            g_config = deepcopy(original_g_config)\n",
    "            g_config.update(a_config)\n",
    "            for m_config in search_model_settings:\n",
    "                for d_config in search_dataset_settings:\n",
    "                    fa_models_config = {\n",
    "                        'features': [[0]],\n",
    "                        'input_size': d_config['observation_days'],\n",
    "                        'output_size': d_config['future_days'],\n",
    "                    }\n",
    "                    search_for_all_models_settings = list(grid_search_params(fa_models_config))\n",
    "                    for fa_models_config in search_for_all_models_settings:\n",
    "                        g_config['run_number'] = len(search_args)\n",
    "                        args = (g_config, d_config, m_config, fa_models_config)\n",
    "                        search_args.append(deepcopy(args))\n",
    "\n",
    "    print(f\"Starting {len(search_args)} processes\")\n",
    "    if pool_size == 1:\n",
    "        for args in search_args:\n",
    "            AttackTSInverseWorker(args[0]['run_number']).worker_process(*args)\n",
    "\n",
    "\n",
    "global_config = {\n",
    "    'logger_service': 'wandb',\n",
    "    'experiment_name': 'ts-inverse_defense_06-07-2024',\n",
    "    'seed': [10], # 28, 80, 71],\n",
    "    'batch_size': 1,\n",
    "    'device': 'cpu',\n",
    "    'verbose': False,\n",
    "    'pool_size': 1,\n",
    "    'run_number': -1,\n",
    "    'total_variation_alpha_inputs': 0, \n",
    "    'total_variation_beta_targets': 0,\n",
    "    'after_effect': 'none',\n",
    "    'warmup_number_of_batches': 0,\n",
    "    'number_of_batches': 1,\n",
    "    'update_model': True, # Update the model in generating gradients from training data\n",
    "    'model_evaluation_during_attack': False, # Baselines do not consider this\n",
    "    'load_lti_model': True,\n",
    "\n",
    "    'dropout': 0,\n",
    "    'optimize_dropout': False,\n",
    "    'dropout_probability_regularizer': 0,\n",
    "    'dummy_init_method': 'rand',\n",
    "}\n",
    "\n",
    "attack_config = [\n",
    "    {\n",
    "        'attack_method': 'TS-Inverse',\n",
    "        # invert attack\n",
    "        'num_learn_epochs': 75,\n",
    "        'learn_learning_rate': 1e-3, \n",
    "        'attack_batch_size': 32,\n",
    "        'inversion_batch_size': 1, # global_config['batch_size'],\n",
    "        'attack_hidden_size': [[768, 512]],\n",
    "        'quantiles': [[0.1, 0.3, 0.7, 0.9]],\n",
    "        'attack_loss': ['quantile'],\n",
    "        'inversion_model': 'ImprovedGradToInputNN_Quantile', \n",
    "        'attack_targets': True,\n",
    "        'learn_optimizer': 'adamW',\n",
    "        'learn_lr_decay': ['on_plateau'],\n",
    "        'aux_dataset': None,\n",
    "        'one_shot_targets': False,\n",
    "\n",
    "\n",
    "        ## Inversion regularization in optimization attack\n",
    "        'inversion_regularization_term_inputs': [1],\n",
    "        'inversion_regularization_term_targets': [0.1],\n",
    "        'inversion_regularization_loss': ['quantile_bounds'],\n",
    "\n",
    "        'lower_res_term_inputs': [0],\n",
    "        'lower_res_term_targets': [0],\n",
    "        'periodicity_term': [1],\n",
    "        'periodicity_loss': ['l1_mean'],\n",
    "        'periodicity_reduce_lr': [False],\n",
    "        'trend_term': [0],\n",
    "        'trend_loss': ['l1_mean'],\n",
    "        'trend_reduce_lr': [False],\n",
    "\n",
    "        ## Optimization attack\n",
    "        'gradient_loss': 'l1', \n",
    "        'base_num_attack_steps': 500,\n",
    "        'after_effect': 'clamp_2',\n",
    "        'optimization_learning_rate': 0.01, \n",
    "        'attack_opti_optimizer': ['adam'],\n",
    "        'attack_opti_lr_decay': ['on_plateau_10'],\n",
    "        'optimize_dropout': True,\n",
    "        'clamp_dropout': 1,\n",
    "        'clamp_dropout_min_max': [[0.0, 1.0]],\n",
    "        'dropout_probability_regularizer': [1e-5], #1e-6, 1e-7, 1e-8],\n",
    "        'dropout_probability_reg_error': 'abs', \n",
    "        'dropout_mask_init_type': 'halves', #['bernoulli', 'halves', 'uniform', 'p', '1-p'], #['halves', 'bernoulli'],\n",
    "        'grad_signs_for_inputs': True,\n",
    "        'grad_signs_for_targets': False,\n",
    "        'grad_signs_for_dropouts': True, #[False, True],\n",
    "    },\n",
    "]\n",
    "\n",
    "dataset_config = [\n",
    "    {\n",
    "        'dataset': 'electricity_370',\n",
    "        'columns': [df_electricity_370.columns.tolist()[4:5]],\n",
    "        'train_stride': 24,\n",
    "        'validation_stride': 1,\n",
    "        'observation_days': 1,\n",
    "        'future_days': 1,\n",
    "        'normalize': 'minmax',\n",
    "    },\n",
    "    {\n",
    "        'dataset': 'london_smartmeter',\n",
    "        'columns': [df_london_smartmeter.columns.tolist()[:1]],\n",
    "        'train_stride': 24, # Is the strides that are attacked\n",
    "        'validation_stride': 1, # Is the stride that is used for training the invertion model\n",
    "        'observation_days': 1,\n",
    "        'future_days': 1,\n",
    "        'normalize': 'minmax',\n",
    "    },\n",
    "    # {\n",
    "    #     'dataset': 'kddcup',\n",
    "    #     'columns': [df_kddcup.columns.tolist()[:1]],\n",
    "    #     'train_stride': 24,\n",
    "    #     'validation_stride': 1,\n",
    "    #     'observation_days': 5,\n",
    "    #     'future_days': 2,\n",
    "    #     'normalize': 'minmax',\n",
    "    # },    \n",
    "]\n",
    "\n",
    "model_config = [\n",
    "    # {\n",
    "    #     '_model': CNN_Predictor,\n",
    "    #     'hidden_size': 64,\n",
    "    #     '_attack_step_multiplier': 10,\n",
    "    # },\n",
    "    # {\n",
    "    #     '_model': FCN_Predictor,\n",
    "    #     'hidden_size': 64,\n",
    "    #     '_attack_step_multiplier': 10,\n",
    "    # },\n",
    "    # {\n",
    "    #     '_model': TCN_Predictor,\n",
    "    #     'hidden_size': 64,\n",
    "    #     'num_levels': 0,\n",
    "    #     'kernel_size': 6,\n",
    "    #     'dilation_factor': 2,\n",
    "    #     'activation': 'relu',\n",
    "    #     'use_weight_norm': True,\n",
    "    #     'init_weights': True,\n",
    "    #     'dropout': 0.1,\n",
    "    #     '_attack_step_multiplier': 10,\n",
    "    # },\n",
    "    {\n",
    "        '_model': JitGRU_Predictor,\n",
    "        'hidden_size': 64,\n",
    "        '_attack_step_multiplier': 10,\n",
    "    },\n",
    "    {\n",
    "        '_model': JitSeq2Seq_Predictor,\n",
    "        'hidden_size': 64,\n",
    "        '_attack_step_multiplier': 10,\n",
    "    }\n",
    "]\n",
    "\n",
    "start_multi_process(global_config, attack_config, dataset_config, model_config, global_config['pool_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
