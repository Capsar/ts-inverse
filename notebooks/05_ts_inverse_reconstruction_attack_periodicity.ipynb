{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_london_smartmeter = pd.read_csv(\"./data/LondonSmartMeter/london_smart_meters_dataset_without_missing_values_first_30_consumers.csv\", index_col='Time', parse_dates=['Time'])\n",
    "df_kddcup = pd.read_csv(\"./data/KDDCup_2018/kdd_cup_2018_dataset_without_missing_values.csv\", index_col='Time', parse_dates=['Time'])\n",
    "df_electricity_321_hourly = pd.read_csv(\"./data/Electricity321Hourly/electricity_hourly_dataset.csv\", index_col='Time', parse_dates=['Time'])\n",
    "df_electricity_370 = pd.read_csv(\"./data/Electricity370/LD2011_2014_first_40_consumers.csv\", index_col='Time', parse_dates=['Time'])\n",
    "# tno_df.head()\n",
    "# print(df.columns.tolist()[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device: NVIDIA GeForce RTX 3090\n",
      "Physical cores: 64\n",
      "Total cores: 128\n",
      "Current Frequency: 2.75Mhz\n",
      "Total: 1007.71 GB\n",
      "Available: 403.55 GB\n",
      "Used: 595.49 GB\n",
      "Percentage: 60.0%\n",
      "Distributed PyTorch available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import psutil\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the current device\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "    device = torch.cuda.current_device()\n",
    "    print(f\"Using CUDA device: {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"CUDA is not available\")\n",
    "\n",
    "print(\"Physical cores:\", psutil.cpu_count(logical=False))\n",
    "print(\"Total cores:\", psutil.cpu_count(logical=True))\n",
    "cpu_freq = psutil.cpu_freq()\n",
    "print(f\"Current Frequency: {cpu_freq.current:.2f}Mhz\")\n",
    "\n",
    "# RAM Information\n",
    "svmem = psutil.virtual_memory()\n",
    "print(f\"Total: {svmem.total / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Available: {svmem.available / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Used: {svmem.used / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Percentage: {svmem.percent}%\")\n",
    "\n",
    "print(\"Distributed PyTorch available:\", torch.distributed.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 60 processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting attack 0 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_ts_regularization_11-6-2024', 'seed': 10, 'batch_size': 4, 'device': 1, 'verbose': False, 'pool_size': 1, 'run_number': 0, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'warmup_number_of_batches': 0, 'number_of_batches': 1, 'update_model': False, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0.1, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'attack_method': 'TS-Inverse', 'num_learn_epochs': 0, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'inversion_regularization_term_inputs': 0, 'inversion_regularization_term_targets': 0, 'inversion_regularization_loss': 'quantile', 'inversion_dilation_loss_alpha_gamma': [0.1, 0.9], 'lower_res_term': 0, 'trend_term': 0, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'periodicity_term': 0, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 500, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, 'num_levels': 4, 'kernel_size': 6, 'dilation_factor': 2, 'activation': 'relu', 'use_weight_norm': True, 'init_weights': True, '_attack_step_multiplier': 10, 'features': [0], 'input_size': 96, 'output_size': 96, 'receptive_field': 151, 'model': 'TCN_Predictor', 'num_attack_steps': 20000, 'train_dataset_size': 569}\n",
      "Starting attack 1 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_ts_regularization_11-6-2024', 'seed': 10, 'batch_size': 4, 'device': 1, 'verbose': False, 'pool_size': 1, 'run_number': 1, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'warmup_number_of_batches': 0, 'number_of_batches': 1, 'update_model': False, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0.1, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'attack_method': 'TS-Inverse', 'num_learn_epochs': 0, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'inversion_regularization_term_inputs': 0, 'inversion_regularization_term_targets': 0, 'inversion_regularization_loss': 'quantile', 'inversion_dilation_loss_alpha_gamma': [0.1, 0.9], 'lower_res_term': 0, 'trend_term': 0, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'periodicity_term': 0, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 500, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'london_smartmeter', 'columns': ['T1'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, 'num_levels': 3, 'kernel_size': 6, 'dilation_factor': 2, 'activation': 'relu', 'use_weight_norm': True, 'init_weights': True, '_attack_step_multiplier': 10, 'features': [0], 'input_size': 48, 'output_size': 48, 'receptive_field': 71, 'model': 'TCN_Predictor', 'num_attack_steps': 20000, 'train_dataset_size': 316}\n",
      "Starting attack 2 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_ts_regularization_11-6-2024', 'seed': 10, 'batch_size': 4, 'device': 1, 'verbose': False, 'pool_size': 1, 'run_number': 2, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'warmup_number_of_batches': 0, 'number_of_batches': 1, 'update_model': False, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0.1, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'attack_method': 'TS-Inverse', 'num_learn_epochs': 0, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'inversion_regularization_term_inputs': 0, 'inversion_regularization_term_targets': 0, 'inversion_regularization_loss': 'quantile', 'inversion_dilation_loss_alpha_gamma': [0.1, 0.9], 'lower_res_term': 0, 'trend_term': 0, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'periodicity_term': 0, 'periodicity_loss': 'l1_mean', 'periodicity_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 500, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'tno_electricity', 'columns': ['12668086_A+'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, 'num_levels': 4, 'kernel_size': 6, 'dilation_factor': 2, 'activation': 'relu', 'use_weight_norm': True, 'init_weights': True, '_attack_step_multiplier': 10, 'features': [0], 'input_size': 96, 'output_size': 96, 'receptive_field': 151, 'model': 'TCN_Predictor', 'num_attack_steps': 20000, 'train_dataset_size': 460}\n",
      "Starting attack 3 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_ts_regularization_11-6-2024', 'seed': 10, 'batch_size': 4, 'device': 1, 'verbose': False, 'pool_size': 1, 'run_number': 3, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'warmup_number_of_batches': 0, 'number_of_batches': 1, 'update_model': False, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0.1, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'attack_method': 'TS-Inverse', 'num_learn_epochs': 0, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'inversion_regularization_term_inputs': 0, 'inversion_regularization_term_targets': 0, 'inversion_regularization_loss': 'quantile', 'inversion_dilation_loss_alpha_gamma': [0.1, 0.9], 'lower_res_term': 0, 'trend_term': 0, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'periodicity_term': 0, 'periodicity_loss': 'l2_mean', 'periodicity_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 500, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'electricity_370', 'columns': ['MT_005'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, 'num_levels': 4, 'kernel_size': 6, 'dilation_factor': 2, 'activation': 'relu', 'use_weight_norm': True, 'init_weights': True, '_attack_step_multiplier': 10, 'features': [0], 'input_size': 96, 'output_size': 96, 'receptive_field': 151, 'model': 'TCN_Predictor', 'num_attack_steps': 20000, 'train_dataset_size': 569}\n",
      "Starting attack 4 with config: {'logger_service': 'wandb', 'experiment_name': 'ts-inverse_ts_regularization_11-6-2024', 'seed': 10, 'batch_size': 4, 'device': 1, 'verbose': False, 'pool_size': 1, 'run_number': 4, 'total_variation_alpha_inputs': 0, 'total_variation_beta_targets': 0, 'after_effect': 'clamp_2', 'warmup_number_of_batches': 0, 'number_of_batches': 1, 'update_model': False, 'model_evaluation_during_attack': False, 'load_lti_model': False, 'dropout': 0.1, 'optimize_dropout': True, 'dropout_probability_regularizer': 1e-05, 'dummy_init_method': 'rand', 'attack_method': 'TS-Inverse', 'num_learn_epochs': 0, 'learn_learning_rate': 0.001, 'attack_batch_size': 32, 'inversion_batch_size': 1, 'attack_hidden_size': [768, 512], 'quantiles': [0.1, 0.3, 0.7, 0.9], 'attack_loss': 'quantile', 'inversion_model': 'ImprovedGradToInputNN_Quantile', 'attack_targets': True, 'learn_optimizer': 'adamW', 'learn_lr_decay': 'on_plateau', 'aux_dataset': None, 'inversion_regularization_term_inputs': 0, 'inversion_regularization_term_targets': 0, 'inversion_regularization_loss': 'quantile', 'inversion_dilation_loss_alpha_gamma': [0.1, 0.9], 'lower_res_term': 0, 'trend_term': 0, 'trend_loss': 'l1_mean', 'trend_reduce_lr': False, 'periodicity_term': 0, 'periodicity_loss': 'l2_mean', 'periodicity_reduce_lr': False, 'gradient_loss': 'l1', 'base_num_attack_steps': 500, 'optimization_learning_rate': 0.01, 'attack_opti_optimizer': 'adam', 'attack_opti_lr_decay': 'on_plateau_10', 'clamp_dropout': 1, 'clamp_dropout_min_max': [0.0, 1.0], 'dropout_mask_init_type': 'halves', 'grad_signs_for_inputs': True, 'grad_signs_for_targets': False, 'grad_signs_for_dropouts': True, 'dataset': 'london_smartmeter', 'columns': ['T1'], 'train_stride': 24, 'validation_stride': 1, 'observation_days': 1, 'future_days': 1, 'normalize': 'minmax', 'hidden_size': 64, 'num_levels': 3, 'kernel_size': 6, 'dilation_factor': 2, 'activation': 'relu', 'use_weight_norm': True, 'init_weights': True, '_attack_step_multiplier': 10, 'features': [0], 'input_size': 48, 'output_size': 48, 'receptive_field': 71, 'model': 'TCN_Predictor', 'num_attack_steps': 20000, 'train_dataset_size': 316}\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from ts_inverse.models import FCN_Predictor, CNN_Predictor, GRU_Predictor, JitGRU_Predictor, CNNJitGRU_Predictor, TCN_Predictor, JitSeq2Seq_Predictor\n",
    "from ts_inverse.utils import grid_search_params\n",
    "from ts_inverse.workers import AttackTSInverseWorker\n",
    "\n",
    "\n",
    "def start_multi_process(g_config, a_config, d_config, m_config, pool_size):\n",
    "    search_args = []\n",
    "    search_configs = list(grid_search_params(g_config))\n",
    "    search_attack_configs = list(grid_search_params(a_config))\n",
    "    search_dataset_settings = list(grid_search_params(d_config))\n",
    "    search_model_settings = list(grid_search_params(m_config))\n",
    "    for original_g_config in search_configs:\n",
    "        for a_config in search_attack_configs:\n",
    "            g_config = deepcopy(original_g_config)\n",
    "            g_config.update(a_config)\n",
    "            for m_config in search_model_settings:\n",
    "                for d_config in search_dataset_settings:\n",
    "                    fa_models_config = {\n",
    "                        'features': [[0]],\n",
    "                        'input_size': d_config['observation_days'],\n",
    "                        'output_size': d_config['future_days'],\n",
    "                    }\n",
    "                    search_for_all_models_settings = list(grid_search_params(fa_models_config))\n",
    "                    for fa_models_config in search_for_all_models_settings:\n",
    "                        g_config['run_number'] = len(search_args)\n",
    "                        args = (g_config, d_config, m_config, fa_models_config)\n",
    "                        search_args.append(deepcopy(args))\n",
    "\n",
    "    print(f\"Starting {len(search_args)} processes\")\n",
    "    if pool_size == 1:\n",
    "        for args in search_args:\n",
    "            AttackTSInverseWorker(args[0]['run_number']).worker_process(*args)\n",
    "\n",
    "\n",
    "global_config = {\n",
    "    'logger_service': 'wandb',\n",
    "    'experiment_name': 'ts-inverse_ts_regularization_11-6-2024',\n",
    "    'seed': [10, 43], # 28, 80, 71],\n",
    "    'batch_size': 4,\n",
    "    'device': 1,\n",
    "    'verbose': False,\n",
    "    'pool_size': 1,\n",
    "    'run_number': -1,\n",
    "    'total_variation_alpha_inputs': 0, \n",
    "    'total_variation_beta_targets': 0,\n",
    "    'after_effect': 'none',\n",
    "    'warmup_number_of_batches': 0,\n",
    "    'number_of_batches': 1,\n",
    "    'update_model': False, # Update the model in generating gradients from training data\n",
    "    'model_evaluation_during_attack': False, # Baselines do not consider this\n",
    "    'load_lti_model': False,\n",
    "\n",
    "    'dropout': 0,\n",
    "    'optimize_dropout': False,\n",
    "    'dropout_probability_regularizer': 0,\n",
    "    'dummy_init_method': 'rand',\n",
    "}\n",
    "\n",
    "attack_config = [\n",
    "    {\n",
    "        'attack_method': 'TS-Inverse',\n",
    "        # invert attack\n",
    "        'num_learn_epochs': 0,\n",
    "        'learn_learning_rate': 1e-3, \n",
    "        'attack_batch_size': 32,\n",
    "        'inversion_batch_size': 1,\n",
    "        'attack_hidden_size': [[768, 512]],\n",
    "        'quantiles': [[0.1, 0.3, 0.7, 0.9]],\n",
    "        'attack_loss': ['quantile'],\n",
    "        'inversion_model': 'ImprovedGradToInputNN_Quantile', \n",
    "        'attack_targets': True,\n",
    "        'learn_optimizer': 'adamW',\n",
    "        'learn_lr_decay': ['on_plateau'],\n",
    "        'aux_dataset': None,\n",
    "\n",
    "        ## Inversion regularization in optimization attack\n",
    "        'inversion_regularization_term_inputs': [0], \n",
    "        'inversion_regularization_term_targets': [0],\n",
    "        'inversion_regularization_loss': ['quantile'],\n",
    "\n",
    "        'lower_res_term': [0],\n",
    "        'trend_term': [0],\n",
    "        'trend_loss': ['l1_mean'],\n",
    "        'trend_reduce_lr': [False],\n",
    "        'periodicity_term': [0, 2, 1, 0.5, 0.1],\n",
    "        'periodicity_loss': ['l1_mean', 'l2_mean'],\n",
    "        'periodicity_reduce_lr': [False],\n",
    "\n",
    "\n",
    "        ## Optimization attack\n",
    "        'gradient_loss': 'l1', \n",
    "        'base_num_attack_steps': 500,\n",
    "        'after_effect': 'clamp_2',\n",
    "        'optimization_learning_rate': 0.01, \n",
    "        'attack_opti_optimizer': ['adam'],\n",
    "        'attack_opti_lr_decay': ['on_plateau_10'],\n",
    "        'optimize_dropout': True,\n",
    "        'clamp_dropout': 1,\n",
    "        'clamp_dropout_min_max': [[0.0, 1.0]],\n",
    "        'dropout_probability_regularizer': [1e-5], #1e-6, 1e-7, 1e-8],\n",
    "        'dropout_mask_init_type': 'halves', #['bernoulli', 'halves', 'uniform', 'p', '1-p'], #['halves', 'bernoulli'],\n",
    "        'grad_signs_for_inputs': True,\n",
    "        'grad_signs_for_targets': False,\n",
    "        'grad_signs_for_dropouts': True, #[False, True],\n",
    "    },\n",
    "]\n",
    "\n",
    "dataset_config = [\n",
    "    {\n",
    "        'dataset': 'electricity_370',\n",
    "        'columns': [df_electricity_370.columns.tolist()[4:5]],\n",
    "        'train_stride': 24,\n",
    "        'validation_stride': 1,\n",
    "        'observation_days': 1,\n",
    "        'future_days': 1,\n",
    "        'normalize': 'minmax',\n",
    "    },\n",
    "    {\n",
    "        'dataset': 'london_smartmeter',\n",
    "        'columns': [df_london_smartmeter.columns.tolist()[:1]],\n",
    "        'train_stride': 24, # Is the strides that are attacked\n",
    "        'validation_stride': 1, # Is the stride that is used for training the invertion model\n",
    "        'observation_days': 1,\n",
    "        'future_days': 1,\n",
    "        'normalize': 'minmax',\n",
    "    },\n",
    "    # {\n",
    "    #     'dataset': 'kddcup',\n",
    "    #     'columns': [df_kddcup.columns.tolist()[:1]],\n",
    "    #     'train_stride': 24,\n",
    "    #     'validation_stride': 1,\n",
    "    #     'observation_days': 5,\n",
    "    #     'future_days': 2,\n",
    "    #     'normalize': 'minmax',\n",
    "    # },    \n",
    "]\n",
    "\n",
    "model_config = [\n",
    "    # {\n",
    "    #     '_model': FCN_Predictor,\n",
    "    #     'hidden_size': 64,\n",
    "    #     '_attack_step_multiplier': 10,\n",
    "    # },\n",
    "    # {\n",
    "    #     '_model': CNN_Predictor,\n",
    "    #     'hidden_size': 64,\n",
    "    #     '_attack_step_multiplier': 10,\n",
    "    # },\n",
    "    {\n",
    "        '_model': TCN_Predictor,\n",
    "        'hidden_size': 64,\n",
    "        'num_levels': 0,\n",
    "        'kernel_size': 6,\n",
    "        'dilation_factor': 2,\n",
    "        'activation': 'relu',\n",
    "        'use_weight_norm': True,\n",
    "        'init_weights': True,\n",
    "        'dropout': 0.1,\n",
    "        '_attack_step_multiplier': 10,\n",
    "    },\n",
    "    # {\n",
    "    #     '_model': JitGRU_Predictor,\n",
    "    #     'hidden_size': 64,\n",
    "    #     '_attack_step_multiplier': 10,\n",
    "    # },\n",
    "    # {\n",
    "    #     '_model': JitSeq2Seq_Predictor,\n",
    "    #     'hidden_size': 64,\n",
    "    #     '_attack_step_multiplier': 10,\n",
    "    # }\n",
    "]\n",
    "\n",
    "start_multi_process(global_config, attack_config, dataset_config, model_config, global_config['pool_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
