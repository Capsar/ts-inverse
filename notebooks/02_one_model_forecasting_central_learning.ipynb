{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_london_smartmeter = pd.read_csv(\"../data/LondonSmartMeter/london_smart_meters_dataset_without_missing_values_first_30_consumers.csv\", index_col='Time', parse_dates=['Time'])\n",
    "df_kddcup = pd.read_csv(\"../data/KDDCup_2018/kdd_cup_2018_dataset_without_missing_values.csv\", index_col='Time', parse_dates=['Time'])\n",
    "df_electricity_321_hourly = pd.read_csv(\"../data/Electricity321Hourly/electricity_hourly_dataset.csv\", index_col='Time', parse_dates=['Time'])\n",
    "df_electricity_370 = pd.read_csv(\"../data/Electricity370/LD2011_2014_first_40_consumers.csv\", index_col='Time', parse_dates=['Time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import psutil\n",
    "import pynvml\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    pynvml.nvmlInit()\n",
    "    # Get the current device\n",
    "    device = 0\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "        utilization = pynvml.nvmlDeviceGetUtilizationRates(handle)\n",
    "        print(\n",
    "            f\"device {i}: {torch.cuda.get_device_properties(i).name} | {torch.cuda.get_device_properties(i).total_memory / (1024**3):.2f} GB | Utilization: {utilization.gpu}%\"\n",
    "        )\n",
    "        device = i\n",
    "\n",
    "    pynvml.nvmlShutdown()\n",
    "    print(f\"Using CUDA device {device}: {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"CUDA is not available\")\n",
    "\n",
    "print(\"Physical cores:\", psutil.cpu_count(logical=False))\n",
    "print(\"Total cores:\", total_cores := psutil.cpu_count(logical=True))\n",
    "\n",
    "core_percentages = [f\"{i}:\\t {percentage}%\\t\" for i, percentage in enumerate(psutil.cpu_percent(percpu=True, interval=1))]\n",
    "core_percentages_formatted = [core_percentages[i : i + 8] for i in range(0, len(core_percentages), 8)]\n",
    "for core_group in core_percentages_formatted:\n",
    "    print(\" \".join(core_group))\n",
    "\n",
    "# RAM Information\n",
    "svmem = psutil.virtual_memory()\n",
    "print(f\"Total: {svmem.total / (1024**3):.2f} GB\")\n",
    "print(f\"Available: {svmem.available / (1024**3):.2f} GB\")\n",
    "print(f\"Used: {svmem.used / (1024**3):.2f} GB\")\n",
    "print(f\"Percentage: {svmem.percent}%\")\n",
    "\n",
    "print(\"Distributed PyTorch available:\", torch.distributed.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from ts_inverse.utils import grid_search_params\n",
    "from ts_inverse.models import FCN_Predictor, CNN_Predictor, GRU_Predictor, TCN_Predictor\n",
    "from ts_inverse.workers import ForecastingWorker\n",
    "\n",
    "def start_multi_process(g_config, d_config, m_config, pool_size):\n",
    "    search_args = []\n",
    "    search_configs = list(grid_search_params(g_config))\n",
    "    search_dataset_settings = list(grid_search_params(d_config))\n",
    "    search_model_settings = list(grid_search_params(m_config))\n",
    "    for g_config in search_configs:\n",
    "        for m_config in search_model_settings:\n",
    "            for d_config in search_dataset_settings:\n",
    "                fa_models_config = {\n",
    "                    'features': [\n",
    "                        # [0, 2, 4], [0, 1, 2], [0, 2]\n",
    "                        # [0], [1], [2], [3], [4], [5],\n",
    "                        # [0, 1], [0, 2], [0, 3], [0, 4], [0, 5],\n",
    "                        # [0, 2, 1], [0, 2, 3], [0, 2, 4], [0, 2, 5],\n",
    "                        # [0, 1, 2, 3], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4, 5]\n",
    "                        # [0, 1, 2]\n",
    "                        [0],\n",
    "                    ],\n",
    "                    'input_size': d_config['observation_days'], # This updated after the dataset is created\n",
    "                    'output_size': d_config['future_days'], # This is updated after the dataset is created\n",
    "                }\n",
    "                search_for_all_models_settings = list(grid_search_params(fa_models_config))\n",
    "                for fa_models_config in search_for_all_models_settings:\n",
    "                    g_config['run_number'] = len(search_args)\n",
    "                    args = (g_config, d_config, m_config, fa_models_config)\n",
    "                    search_args.append(deepcopy(args))\n",
    "\n",
    "    print(f\"Starting {len(search_args)} processes\")\n",
    "    if pool_size == 1:\n",
    "        for i, args in enumerate(search_args):\n",
    "            ForecastingWorker(args[0]['run_number']).worker_process(*args)\n",
    "\n",
    "global_config = {\n",
    "    'logger_service': 'wandb',\n",
    "    'experiment_name': 'forecasting_experiment_3-3-2025',\n",
    "    'seed': [10],\n",
    "    'early_stopping_patience': 1000,\n",
    "    'early_stopping_min_delta': 0.001,\n",
    "    'num_epochs': 100,\n",
    "    'batch_size': 1,\n",
    "    'learning_rate': 0.001,\n",
    "    'device': 1,\n",
    "    'verbose': False,\n",
    "    'pool_size': 1,\n",
    "    'run_number': -1\n",
    "}\n",
    "\n",
    "dataset_config = [\n",
    "    {\n",
    "        'dataset': 'electricity_370',\n",
    "        'columns': [df_electricity_370.columns.tolist()[4:5]],\n",
    "        'train_stride': 24,\n",
    "        'observation_days': 1,\n",
    "        'future_days': 1,\n",
    "        'normalize': 'minmax',\n",
    "    },\n",
    "\n",
    "    # {\n",
    "    #     'dataset': 'electricity_370',\n",
    "    #     'columns': [df_electricity_370.columns.tolist()[4:5], df_electricity_370.columns.tolist()[4:10]],\n",
    "    #     'train_stride': [24, 4, 1],\n",
    "    #     'validation_stride': 1,\n",
    "    #     'observation_days': [1, 7, 14, 28],\n",
    "    #     'future_days': 1,\n",
    "    #     'normalize': 'minmax',\n",
    "    # },\n",
    "    # {\n",
    "    #     'dataset': 'london_smartmeter',\n",
    "    #     'columns': [df_london_smartmeter.columns.tolist()[:1]],\n",
    "    #     'train_stride': 24,\n",
    "    #     'observation_days': 1,\n",
    "    #     'future_days': 1,\n",
    "    #     'normalize': 'minmax',\n",
    "    # },\n",
    "    # {\n",
    "    #     'dataset': 'kddcup',\n",
    "    #     'columns': [df_kddcup.columns.tolist()[:1]],\n",
    "    #     'train_stride': 24,\n",
    "    #     'observation_days': 5,\n",
    "    #     'future_days': 2,\n",
    "    #     'normalize': 'minmax',\n",
    "    # },\n",
    "]\n",
    "\n",
    "model_config = [\n",
    "    # {\n",
    "    #     '_model': TCN_Predictor,\n",
    "    #     'hidden_size': 64,\n",
    "    #     'num_levels': 0,\n",
    "    #     'kernel_size': 4,\n",
    "    #     'dilation_factor': 2,\n",
    "    #     'activation': 'relu',\n",
    "    #     'use_weight_norm': True,\n",
    "    #     'init_weights': True\n",
    "    # },\n",
    "    {\n",
    "        '_model': FCN_Predictor,\n",
    "        'hidden_size': 64,\n",
    "    }, \n",
    "    # {\n",
    "    #     '_model': CNN_Predictor,\n",
    "    #     'hidden_size': 64,\n",
    "    # },\n",
    "    # {\n",
    "    #     '_model': GRU_Predictor,\n",
    "    #     'hidden_size': 64,\n",
    "    # }\n",
    "]\n",
    "start_multi_process(global_config, dataset_config, model_config, pool_size=global_config['pool_size'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
